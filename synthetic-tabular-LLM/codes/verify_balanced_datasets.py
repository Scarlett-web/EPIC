"""
éªŒè¯ç”Ÿæˆçš„å¹³è¡¡æ•°æ®é›†
"""

import pandas as pd
from pathlib import Path

# é…ç½®è·¯å¾„
BALANCED_DIR = Path('../data/balanced_datasets')

# æ•°æ®é›†é…ç½®
DATASETS = {
    'Sick': {
        'target_column': 'Class',
        'files': [
            'Sick_balanced_CTGAN_conditional.csv',
            'Sick_balanced_TVAE_conditional.csv',
            'Sick_balanced_CTGAN_rejection.csv',
            'Sick_balanced_TVAE_rejection.csv',
        ]
    },
    'Travel': {
        'target_column': 'Target',
        'files': [
            'Travel_balanced_CTGAN_conditional.csv',
            'Travel_balanced_TVAE_conditional.csv',
            'Travel_balanced_CTGAN_rejection.csv',
            'Travel_balanced_TVAE_rejection.csv',
        ]
    },
    'HELOC': {
        'target_column': 'RiskPerformance',
        'files': [
            'HELOC_balanced_CTGAN_conditional.csv',
            'HELOC_balanced_TVAE_conditional.csv',
            'HELOC_balanced_CTGAN_rejection.csv',
            'HELOC_balanced_TVAE_rejection.csv',
        ]
    }
}

def verify_dataset(dataset_name, config):
    """éªŒè¯å•ä¸ªæ•°æ®é›†çš„æ‰€æœ‰å¹³è¡¡æ–‡ä»¶"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š éªŒè¯ {dataset_name} æ•°æ®é›†")
    print(f"{'='*60}")
    
    dataset_dir = BALANCED_DIR / dataset_name
    target_column = config['target_column']
    
    results = []
    
    for filename in config['files']:
        filepath = dataset_dir / filename
        
        if not filepath.exists():
            print(f"\nâŒ {filename}: æ–‡ä»¶ä¸å­˜åœ¨")
            continue
        
        # è¯»å–æ•°æ®
        df = pd.read_csv(filepath)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_samples = len(df)
        class_counts = df[target_column].value_counts()
        
        # è®¡ç®—ä¸å¹³è¡¡æ¯”ä¾‹
        max_count = class_counts.max()
        min_count = class_counts.min()
        imbalance_ratio = max_count / min_count
        
        # åˆ¤æ–­å¹³è¡¡æ€§
        if imbalance_ratio < 1.1:
            balance_status = "âœ… å®Œç¾å¹³è¡¡"
        elif imbalance_ratio < 1.5:
            balance_status = "âœ… è½»åº¦ä¸å¹³è¡¡"
        elif imbalance_ratio < 3.0:
            balance_status = "âš ï¸ ä¸­åº¦ä¸å¹³è¡¡"
        else:
            balance_status = "âŒ ä¸¥é‡ä¸å¹³è¡¡"
        
        print(f"\nğŸ“„ {filename}")
        print(f"   æ€»æ ·æœ¬æ•°: {total_samples}")
        print(f"   ç±»åˆ«åˆ†å¸ƒ:")
        for cls, count in class_counts.items():
            percentage = count / total_samples * 100
            print(f"     {cls}: {count} ({percentage:.1f}%)")
        print(f"   ä¸å¹³è¡¡æ¯”ä¾‹: {imbalance_ratio:.2f}:1")
        print(f"   å¹³è¡¡çŠ¶æ€: {balance_status}")
        
        results.append({
            'dataset': dataset_name,
            'file': filename,
            'samples': total_samples,
            'imbalance_ratio': imbalance_ratio,
            'status': balance_status
        })
    
    return results

# ä¸»ç¨‹åº
if __name__ == '__main__':
    print("="*60)
    print("ğŸ” éªŒè¯æ‰€æœ‰å¹³è¡¡æ•°æ®é›†")
    print("="*60)
    
    all_results = []
    
    for dataset_name, config in DATASETS.items():
        results = verify_dataset(dataset_name, config)
        all_results.extend(results)
    
    # æ€»ç»“
    print(f"\n{'='*60}")
    print("ğŸ“Š éªŒè¯æ€»ç»“")
    print(f"{'='*60}\n")
    
    # æŒ‰æ•°æ®é›†åˆ†ç»„ç»Ÿè®¡
    for dataset_name in DATASETS.keys():
        dataset_results = [r for r in all_results if r['dataset'] == dataset_name]
        print(f"{dataset_name}:")
        for result in dataset_results:
            print(f"  {result['status']} {result['file']}")
            print(f"     æ ·æœ¬æ•°: {result['samples']}, ä¸å¹³è¡¡æ¯”ä¾‹: {result['imbalance_ratio']:.2f}:1")
        print()
    
    # ç»Ÿè®¡å®Œç¾å¹³è¡¡çš„æ•°æ®é›†æ•°é‡
    perfect_balance = sum(1 for r in all_results if r['imbalance_ratio'] < 1.1)
    print(f"âœ… å®Œç¾å¹³è¡¡æ•°æ®é›†: {perfect_balance}/{len(all_results)}")
    print(f"ğŸ“ æ‰€æœ‰æ•°æ®é›†ä½ç½®: {BALANCED_DIR}")
    print(f"\nğŸ‰ éªŒè¯å®Œæˆï¼")

