"""
ğŸš€ Travel æ•°æ®é›†æ·±åº¦å­¦ä¹ åŸºçº¿ (CTGAN & TVAE) - ç®€åŒ–ç‰ˆ
"""
import pandas as pd
import numpy as np
import time
import warnings
from sdv.single_table import CTGANSynthesizer, TVAESynthesizer
from sdv.metadata import SingleTableMetadata
from xgboost import XGBClassifier
from sklearn.metrics import f1_score, balanced_accuracy_score
from sklearn.preprocessing import LabelEncoder

warnings.filterwarnings('ignore')

# é…ç½®
DATA_DIR = '../data/realdata/travel'
SAVE_DIR = '../data/syndata'
SAMPLES_TO_GENERATE = 1000
EPOCHS = 50  # å‡å°‘åˆ° 50 è½®ä»¥åŠ å¿«é€Ÿåº¦
TARGET_COLUMN = 'Target'

print("=" * 60)
print("ğŸš€ Travel æ•°æ®é›†æ·±åº¦å­¦ä¹ åŸºçº¿ (CTGAN & TVAE)")
print("=" * 60)

# 1. è¯»å–æ•°æ®
print("\n[1/6] æ­£åœ¨è¯»å–æ•°æ®...")
X_train = pd.read_csv(f'{DATA_DIR}/X_train.csv', index_col=0)
y_train = pd.read_csv(f'{DATA_DIR}/y_train.csv', index_col=0)
X_test = pd.read_csv(f'{DATA_DIR}/X_test.csv', index_col=0)
y_test = pd.read_csv(f'{DATA_DIR}/y_test.csv', index_col=0).values.ravel()

print(f"   è®­ç»ƒé›†: {X_train.shape[0]} æ¡, æµ‹è¯•é›†: {X_test.shape[0]} æ¡")
print(f"   ç±»åˆ«åˆ†å¸ƒ: {dict(pd.Series(y_train[TARGET_COLUMN]).value_counts())}")

# åˆå¹¶æ•°æ®
train_data = pd.concat([X_train, y_train], axis=1)

# æ ‡ç­¾ç¼–ç 
le_y = LabelEncoder()
y_test_enc = le_y.fit_transform(y_test)
minority_class = np.argmin(np.bincount(y_test_enc))

# 2. æ£€æµ‹å…ƒæ•°æ®
print("\n[2/6] æ­£åœ¨æ£€æµ‹æ•°æ®ç»“æ„...")
metadata = SingleTableMetadata()
metadata.detect_from_dataframe(train_data)
print("   âœ… å…ƒæ•°æ®æ£€æµ‹å®Œæˆ")

# è¯„ä¼°å‡½æ•°
def evaluate_synthetic_data(name, synthetic_data):
    print(f"\n   è¯„ä¼° {name} ç”Ÿæˆçš„æ•°æ®...")
    
    X_syn = synthetic_data.drop(TARGET_COLUMN, axis=1)
    y_syn = synthetic_data[TARGET_COLUMN]
    
    print(f"   ç”Ÿæˆæ•°æ®: {X_syn.shape[0]} æ¡")
    print(f"   ç±»åˆ«åˆ†å¸ƒ: {dict(y_syn.value_counts())}")
    
    # æ•°æ®ç¼–ç 
    full_X = pd.concat([X_train, X_test, X_syn], axis=0)
    encoders = {}
    
    for col in X_train.columns:
        if X_train[col].dtype == 'object' or X_train[col].nunique() < 10:
            le = LabelEncoder()
            full_X[col] = full_X[col].astype(str).fillna('Missing')
            le.fit(full_X[col])
            X_syn[col] = le.transform(X_syn[col].astype(str).fillna('Missing'))
            encoders[col] = le
    
    y_syn_enc = le_y.transform(y_syn)
    
    # æ··åˆè®­ç»ƒ
    X_train_enc = X_train.copy()
    for col, le in encoders.items():
        X_train_enc[col] = le.transform(X_train_enc[col].astype(str).fillna('Missing'))
    
    X_final = pd.concat([X_train_enc, X_syn], axis=0)
    y_final = np.concatenate([le_y.transform(y_train.values.ravel()), y_syn_enc])
    
    # è®­ç»ƒ XGBoost
    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, verbosity=0)
    model.fit(X_final, y_final)
    
    # é¢„æµ‹
    X_test_encoded = X_test.copy()
    for col, le in encoders.items():
        X_test_encoded[col] = le.transform(X_test_encoded[col].astype(str).fillna('Missing'))
    
    y_pred = model.predict(X_test_encoded)
    
    f1 = f1_score(y_test_enc, y_pred, pos_label=minority_class)
    ba = balanced_accuracy_score(y_test_enc, y_pred)
    
    print(f"   F1 Score: {f1:.4f}, Balanced Acc: {ba:.4f}")
    return f1, ba

# 3. è®­ç»ƒ CTGAN
print("\n" + "=" * 60)
print("[3/6] å¼€å§‹è®­ç»ƒ CTGAN")
print("=" * 60)
print(f"   è®­ç»ƒè½®æ•°: {EPOCHS}, ç›®æ ‡ç”Ÿæˆ: {SAMPLES_TO_GENERATE} æ¡")

start_time = time.time()
ctgan = CTGANSynthesizer(metadata, epochs=EPOCHS, verbose=True)
print("   å¼€å§‹è®­ç»ƒ...")
ctgan.fit(train_data)
train_time = time.time() - start_time

print(f"\n   âœ… CTGAN è®­ç»ƒå®Œæˆï¼è€—æ—¶: {train_time/60:.2f} åˆ†é’Ÿ")
print(f"   æ­£åœ¨ç”Ÿæˆæ•°æ®...")

syn_ctgan = ctgan.sample(num_rows=SAMPLES_TO_GENERATE)
syn_ctgan.to_csv(f"{SAVE_DIR}/Travel_CTGAN_samples.csv", index=False)
print(f"   âœ… å·²ä¿å­˜: {SAVE_DIR}/Travel_CTGAN_samples.csv")

f1_ctgan, ba_ctgan = evaluate_synthetic_data("CTGAN", syn_ctgan)

# 4. è®­ç»ƒ TVAE
print("\n" + "=" * 60)
print("[4/6] å¼€å§‹è®­ç»ƒ TVAE")
print("=" * 60)

start_time = time.time()
tvae = TVAESynthesizer(metadata, epochs=EPOCHS, verbose=True)
print("   å¼€å§‹è®­ç»ƒ...")
tvae.fit(train_data)
train_time = time.time() - start_time

print(f"\n   âœ… TVAE è®­ç»ƒå®Œæˆï¼è€—æ—¶: {train_time/60:.2f} åˆ†é’Ÿ")
print(f"   æ­£åœ¨ç”Ÿæˆæ•°æ®...")

syn_tvae = tvae.sample(num_rows=SAMPLES_TO_GENERATE)
syn_tvae.to_csv(f"{SAVE_DIR}/Travel_TVAE_samples.csv", index=False)
print(f"   âœ… å·²ä¿å­˜: {SAVE_DIR}/Travel_TVAE_samples.csv")

f1_tvae, ba_tvae = evaluate_synthetic_data("TVAE", syn_tvae)

# 5. æ€»ç»“
print("\n" + "=" * 60)
print("âœ… [5/6] æ‰€æœ‰æ·±åº¦å­¦ä¹ åŸºçº¿è¿è¡Œå®Œæ¯•ï¼")
print("=" * 60)
print(f"\nğŸ“Š æœ€ç»ˆç»“æœå¯¹æ¯”:")
print(f"   CTGAN - F1: {f1_ctgan:.4f}, Balanced Acc: {ba_ctgan:.4f}")
print(f"   TVAE  - F1: {f1_tvae:.4f}, Balanced Acc: {ba_tvae:.4f}")
print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
print(f"   - {SAVE_DIR}/Travel_CTGAN_samples.csv")
print(f"   - {SAVE_DIR}/Travel_TVAE_samples.csv")
print("\nğŸ‰ å®Œæˆï¼")
print("=" * 60)

