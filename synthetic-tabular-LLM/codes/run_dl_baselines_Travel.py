"""
ğŸš€ Travel æ•°æ®é›†æ·±åº¦å­¦ä¹ åŸºçº¿ (CTGAN & TVAE)
è¿è¡Œ CTGAN å’Œ TVAE ç”Ÿæˆåˆæˆæ•°æ®ï¼Œå¹¶è¯„ä¼°è´¨é‡
"""
import pandas as pd
import numpy as np
import time
import warnings
from sdv.single_table import CTGANSynthesizer, TVAESynthesizer
from sdv.metadata import SingleTableMetadata
from xgboost import XGBClassifier
from sklearn.metrics import f1_score, classification_report
from sklearn.preprocessing import LabelEncoder

warnings.filterwarnings('ignore')

# ================= é…ç½®åŒºåŸŸ =================
DATA_DIR = '../data/realdata/travel'  # Travel æ•°æ®é›†è·¯å¾„
SAVE_DIR = '../data/syndata'
SAMPLES_TO_GENERATE = 1000  # ç”Ÿæˆ 1000 æ¡æ•°æ®
EPOCHS = 100                # è®­ç»ƒè½®æ•° (å¯ä»¥æ”¹å°ï¼Œæ¯”å¦‚ 50)
TARGET_COLUMN = 'Target'    # Travel æ•°æ®é›†çš„ç›®æ ‡åˆ—
# ===========================================

import sys
sys.stdout.reconfigure(line_buffering=True)

print("="*60, flush=True)
print("ğŸš€ Travel æ•°æ®é›†æ·±åº¦å­¦ä¹ åŸºçº¿ (CTGAN & TVAE)", flush=True)
print("="*60, flush=True)

print("\nğŸ“‚ [1/5] æ­£åœ¨è¯»å–åŸå§‹æ•°æ®...", flush=True)
try:
    X_train = pd.read_csv(f'{DATA_DIR}/X_train.csv', index_col=0)
    y_train = pd.read_csv(f'{DATA_DIR}/y_train.csv', index_col=0)
    X_test = pd.read_csv(f'{DATA_DIR}/X_test.csv', index_col=0)
    y_test = pd.read_csv(f'{DATA_DIR}/y_test.csv', index_col=0).values.ravel()
    
    print(f"   âœ… è®­ç»ƒé›†: {X_train.shape[0]} æ¡")
    print(f"   âœ… æµ‹è¯•é›†: {X_test.shape[0]} æ¡")
    print(f"   âœ… ç‰¹å¾æ•°: {X_train.shape[1]} ä¸ª")
    
    # åˆå¹¶ X å’Œ yï¼Œå› ä¸ºç”Ÿæˆæ¨¡å‹éœ€è¦å­¦ä¹ æ•´å¼ è¡¨
    train_data = pd.concat([X_train, y_train], axis=1)
    
    # æŸ¥çœ‹ç±»åˆ«åˆ†å¸ƒ
    print(f"\n   ğŸ“Š è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ:")
    print(f"      {y_train[TARGET_COLUMN].value_counts().to_dict()}")
    
    # æ ‡ç­¾ç¼–ç  (XGBoostè¯„ä¼°ç”¨)
    le_y = LabelEncoder()
    y_test_enc = le_y.fit_transform(y_test)
    minority_class = np.argmin(np.bincount(y_test_enc))
    print(f"   ğŸ¯ å°‘æ•°ç±»æ ‡ç­¾: {minority_class}")
    
except FileNotFoundError as e:
    print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ï¼")
    print(f"   è¯·ç¡®ä¿å·²è¿è¡Œ preprocess_travel_data.py")
    print(f"   é”™è¯¯è¯¦æƒ…: {e}")
    exit()

# è‡ªåŠ¨æ£€æµ‹å…ƒæ•°æ® (å‘Šè¯‰æ¨¡å‹å“ªäº›åˆ—æ˜¯åˆ†ç±»ï¼Œå“ªäº›æ˜¯æ•°å€¼)
print("\nğŸ” [2/5] æ­£åœ¨è‡ªåŠ¨æ£€æµ‹æ•°æ®ç»“æ„...")
metadata = SingleTableMetadata()
metadata.detect_from_dataframe(train_data)
print("   âœ… å…ƒæ•°æ®æ£€æµ‹å®Œæˆ")

# å®šä¹‰ä¸€ä¸ªé€šç”¨çš„è¯„ä¼°å‡½æ•°
def evaluate_synthetic_data(name, synthetic_data):
    print(f"\nğŸ“Š æ­£åœ¨è¯„ä¼° {name} ç”Ÿæˆçš„æ•°æ®è´¨é‡...")
    
    # 1. å‡†å¤‡åˆæˆæ•°æ®çš„ X å’Œ y
    X_syn = synthetic_data.drop(TARGET_COLUMN, axis=1)
    y_syn = synthetic_data[TARGET_COLUMN]
    
    print(f"   ç”Ÿæˆæ•°æ®å½¢çŠ¶: {X_syn.shape}")
    print(f"   ç”Ÿæˆæ•°æ®ç±»åˆ«åˆ†å¸ƒ: {y_syn.value_counts().to_dict()}")
    
    # 2. æ•°æ®é¢„å¤„ç† (è½¬æ•°å­—)
    # åˆå¹¶æ‰€æœ‰æ•°æ®ä»¥ç»Ÿä¸€ç¼–ç 
    full_X = pd.concat([X_train, X_test, X_syn], axis=0)
    
    # è®­ç»ƒç¼–ç å™¨
    encoders = {}
    for col in X_train.columns:
        if X_train[col].dtype == 'object' or X_train[col].nunique() < 10:
            le = LabelEncoder()
            full_X[col] = full_X[col].astype(str).fillna('Missing')
            le.fit(full_X[col])
            
            # è½¬æ¢åˆæˆæ•°æ®
            X_syn[col] = le.transform(X_syn[col].astype(str).fillna('Missing'))
            encoders[col] = le
    
    # è½¬æ¢æ ‡ç­¾
    y_syn_enc = le_y.transform(y_syn)
    
    # 3. æ··åˆæ•°æ®è®­ç»ƒ (Real + Synthetic)
    X_train_enc = X_train.copy()
    for col, le in encoders.items():
        X_train_enc[col] = le.transform(X_train_enc[col].astype(str).fillna('Missing'))
        
    X_final = pd.concat([X_train_enc, X_syn], axis=0)
    y_final = np.concatenate([le_y.transform(y_train.values.ravel()), y_syn_enc])
    
    print(f"   æ··åˆè®­ç»ƒé›†å¤§å°: {X_final.shape[0]} æ¡")
    
    # 4. è®­ç»ƒ XGBoost
    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
    model.fit(X_final, y_final)
    
    # 5. é¢„æµ‹
    X_test_encoded = X_test.copy()
    for col, le in encoders.items():
        X_test_encoded[col] = le.transform(X_test_encoded[col].astype(str).fillna('Missing'))
        
    y_pred = model.predict(X_test_encoded)
    
    f1 = f1_score(y_test_enc, y_pred, pos_label=minority_class)
    return f1

# ===========================================
# ğŸ¤– æ¨¡å‹ 1: CTGAN
# ===========================================
print("\n" + "="*60)
print("ğŸ¤– [3/5] å¼€å§‹è®­ç»ƒ CTGAN (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
print("="*60)
start_time = time.time()

ctgan = CTGANSynthesizer(metadata, epochs=EPOCHS, verbose=True)
ctgan.fit(train_data)

print(f"\n   âœ… CTGAN è®­ç»ƒå®Œæˆï¼è€—æ—¶: {time.time() - start_time:.1f} ç§’")
print(f"   æ­£åœ¨ç”Ÿæˆ {SAMPLES_TO_GENERATE} æ¡æ•°æ®...")

syn_ctgan = ctgan.sample(num_rows=SAMPLES_TO_GENERATE)
syn_ctgan.to_csv(f"{SAVE_DIR}/Travel_CTGAN_samples.csv", index=False)
print(f"   âœ… æ•°æ®å·²ä¿å­˜åˆ°: {SAVE_DIR}/Travel_CTGAN_samples.csv")

f1_ctgan = evaluate_synthetic_data("CTGAN", syn_ctgan)
print(f"\nğŸ† CTGAN (Real+Syn) F1 Score: {f1_ctgan:.4f}")

# ===========================================
# ğŸ¤– æ¨¡å‹ 2: TVAE
# ===========================================
print("\n" + "="*60)
print("ğŸ¤– [4/5] å¼€å§‹è®­ç»ƒ TVAE (é€šå¸¸æ¯” CTGAN å¿«)...")
print("="*60)
start_time = time.time()

tvae = TVAESynthesizer(metadata, epochs=EPOCHS, verbose=True)
tvae.fit(train_data)

print(f"\n   âœ… TVAE è®­ç»ƒå®Œæˆï¼è€—æ—¶: {time.time() - start_time:.1f} ç§’")
print(f"   æ­£åœ¨ç”Ÿæˆ {SAMPLES_TO_GENERATE} æ¡æ•°æ®...")

syn_tvae = tvae.sample(num_rows=SAMPLES_TO_GENERATE)
syn_tvae.to_csv(f"{SAVE_DIR}/Travel_TVAE_samples.csv", index=False)
print(f"   âœ… æ•°æ®å·²ä¿å­˜åˆ°: {SAVE_DIR}/Travel_TVAE_samples.csv")

f1_tvae = evaluate_synthetic_data("TVAE", syn_tvae)
print(f"\nğŸ† TVAE (Real+Syn) F1 Score: {f1_tvae:.4f}")

# ===========================================
# ğŸ“Š æœ€ç»ˆæ€»ç»“
# ===========================================
print("\n" + "="*60)
print("âœ… [5/5] æ‰€æœ‰æ·±åº¦å­¦ä¹ åŸºçº¿è¿è¡Œå®Œæ¯•ï¼")
print("="*60)
print(f"\nğŸ“Š æœ€ç»ˆç»“æœå¯¹æ¯”:")
print(f"   CTGAN F1 Score: {f1_ctgan:.4f}")
print(f"   TVAE  F1 Score: {f1_tvae:.4f}")
print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
print(f"   - {SAVE_DIR}/Travel_CTGAN_samples.csv")
print(f"   - {SAVE_DIR}/Travel_TVAE_samples.csv")
print("\nğŸ‰ å®Œæˆï¼å¯ä»¥ä½¿ç”¨è¿™äº›åˆæˆæ•°æ®è¿›è¡Œä¸‹æ¸¸ä»»åŠ¡è¯„ä¼°ã€‚")
print("="*60)

