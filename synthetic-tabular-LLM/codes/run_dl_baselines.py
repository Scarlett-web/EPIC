import pandas as pd
import numpy as np
import time
import warnings
from sdv.single_table import CTGANSynthesizer, TVAESynthesizer
from sdv.metadata import SingleTableMetadata
from xgboost import XGBClassifier
from sklearn.metrics import f1_score, classification_report
from sklearn.preprocessing import LabelEncoder

warnings.filterwarnings('ignore')

# ================= é…ç½®åŒºåŸŸ =================
DATA_DIR = '../data/realdata/Sick'
SAVE_DIR = '../data/syndata'
SAMPLES_TO_GENERATE = 1000  # è®ºæ–‡è¦æ±‚ç”Ÿæˆ 1K
EPOCHS = 100                # è®­ç»ƒè½®æ•° (ç”µè„‘æ…¢å¯ä»¥æ”¹å°ï¼Œæ¯”å¦‚ 50)
# ===========================================

print("ğŸš€ [1/5] æ­£åœ¨è¯»å–åŸå§‹æ•°æ®...")
try:
    X_train = pd.read_csv(f'{DATA_DIR}/X_train.csv', index_col=0)
    y_train = pd.read_csv(f'{DATA_DIR}/y_train.csv', index_col=0)
    X_test = pd.read_csv(f'{DATA_DIR}/X_test.csv', index_col=0)
    y_test = pd.read_csv(f'{DATA_DIR}/y_test.csv', index_col=0).values.ravel()
    
    # åˆå¹¶ X å’Œ yï¼Œå› ä¸ºç”Ÿæˆæ¨¡å‹éœ€è¦å­¦ä¹ æ•´å¼ è¡¨
    train_data = pd.concat([X_train, y_train], axis=1)
    
    # æ ‡ç­¾ç¼–ç  (XGBoostè¯„ä¼°ç”¨)
    le_y = LabelEncoder()
    y_test_enc = le_y.fit_transform(y_test)
    minority_class = np.argmin(np.bincount(y_test_enc)) # è‡ªåŠ¨æ‰¾å°‘æ•°ç±»
    
except FileNotFoundError:
    print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ï¼")
    exit()

# è‡ªåŠ¨æ£€æµ‹å…ƒæ•°æ® (å‘Šè¯‰æ¨¡å‹å“ªäº›åˆ—æ˜¯åˆ†ç±»ï¼Œå“ªäº›æ˜¯æ•°å€¼)
print("    æ­£åœ¨è‡ªåŠ¨æ£€æµ‹æ•°æ®ç»“æ„...")
metadata = SingleTableMetadata()
metadata.detect_from_dataframe(train_data)

# å®šä¹‰ä¸€ä¸ªé€šç”¨çš„è¯„ä¼°å‡½æ•°
def evaluate_synthetic_data(name, synthetic_data):
    print(f"\nğŸ“Š æ­£åœ¨è¯„ä¼° {name} ç”Ÿæˆçš„æ•°æ®è´¨é‡...")
    
    # 1. å‡†å¤‡åˆæˆæ•°æ®çš„ X å’Œ y
    X_syn = synthetic_data.drop('Class', axis=1)
    y_syn = synthetic_data['Class']
    
    # 2. æ•°æ®é¢„å¤„ç† (å’Œä¹‹å‰ä¸€æ ·ï¼Œè½¬æ•°å­—)
    # åˆå¹¶æ‰€æœ‰æ•°æ®ä»¥ç»Ÿä¸€ç¼–ç 
    full_X = pd.concat([X_train, X_test, X_syn], axis=0)
    
    # è®­ç»ƒç¼–ç å™¨
    encoders = {}
    for col in X_train.columns:
        if X_train[col].dtype == 'object' or X_train[col].nunique() < 10:
            le = LabelEncoder()
            full_X[col] = full_X[col].astype(str).fillna('Missing')
            le.fit(full_X[col])
            
            # è½¬æ¢åˆæˆæ•°æ®å’Œæµ‹è¯•é›†
            X_syn[col] = le.transform(X_syn[col].astype(str).fillna('Missing'))
            X_test_enc = X_test.copy() # ä¸´æ—¶å‰¯æœ¬
            X_test_enc[col] = le.transform(X_test[col].astype(str).fillna('Missing'))
            encoders[col] = le
    
    # è½¬æ¢æ ‡ç­¾
    y_syn_enc = le_y.transform(y_syn)
    
    # 3. æ··åˆæ•°æ®è®­ç»ƒ (Real + Synthetic)
    # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åªç”¨åˆæˆæ•°æ®è®­ç»ƒï¼Œçœ‹çœ‹å®ƒè‡ªå·±èƒ½ä¸èƒ½æ‰“
    # (å¦‚æœæƒ³å¤ç°è®ºæ–‡çš„ +Augmentï¼Œå¯ä»¥æŠŠ X_train å’Œ X_syn æ‹¼èµ·æ¥)
    X_train_enc = X_train.copy()
    for col, le in encoders.items():
        X_train_enc[col] = le.transform(X_train_enc[col].astype(str).fillna('Missing'))
        
    X_final = pd.concat([X_train_enc, X_syn], axis=0)
    y_final = np.concatenate([le_y.transform(y_train.values.ravel()), y_syn_enc])
    
    # 4. è®­ç»ƒ XGBoost
    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
    model.fit(X_final, y_final)
    
    # 5. é¢„æµ‹
    # æ³¨æ„ï¼šéœ€è¦é‡æ–°å¯¹ X_test è¿›è¡Œç¼–ç åŒ¹é…
    X_test_encoded = X_test.copy()
    for col, le in encoders.items():
        X_test_encoded[col] = le.transform(X_test_encoded[col].astype(str).fillna('Missing'))
        
    y_pred = model.predict(X_test_encoded)
    
    return f1_score(y_test_enc, y_pred, pos_label=minority_class)

# ===========================================
# ğŸ¤– æ¨¡å‹ 1: CTGAN
# ===========================================
print("\n" + "="*40)
print("ğŸ¤– å¼€å§‹è®­ç»ƒ CTGAN (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
print("="*40)
ctgan = CTGANSynthesizer(metadata, epochs=EPOCHS, verbose=True)
ctgan.fit(train_data)

print("    æ­£åœ¨ç”Ÿæˆ 1000 æ¡æ•°æ®...")
syn_ctgan = ctgan.sample(num_rows=SAMPLES_TO_GENERATE)
syn_ctgan.to_csv(f"{SAVE_DIR}/Sick_CTGAN_samples.csv", index=False)

f1_ctgan = evaluate_synthetic_data("CTGAN", syn_ctgan)
print(f"ğŸ† CTGAN (Real+Syn) F1 Score: {f1_ctgan:.4f}")

# ===========================================
# ğŸ¤– æ¨¡å‹ 2: TVAE
# ===========================================
print("\n" + "="*40)
print("ğŸ¤– å¼€å§‹è®­ç»ƒ TVAE (é€šå¸¸æ¯” CTGAN å¿«)...")
print("="*40)
tvae = TVAESynthesizer(metadata, epochs=EPOCHS, verbose=True)
tvae.fit(train_data)

print("    æ­£åœ¨ç”Ÿæˆ 1000 æ¡æ•°æ®...")
syn_tvae = tvae.sample(num_rows=SAMPLES_TO_GENERATE)
syn_tvae.to_csv(f"{SAVE_DIR}/Sick_TVAE_samples.csv", index=False)

f1_tvae = evaluate_synthetic_data("TVAE", syn_tvae)
print(f"ğŸ† TVAE (Real+Syn) F1 Score: {f1_tvae:.4f}")

print("\n" + "="*40)
print("âœ… æ‰€æœ‰æ·±åº¦å­¦ä¹ åŸºçº¿è¿è¡Œå®Œæ¯•ï¼")